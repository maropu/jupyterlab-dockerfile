{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.snorkel.org/get-started/\n",
    "pd.set_option(\"display.max_colwidth\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label mappings for convenience\n",
    "ABSTAIN = -1\n",
    "NOT_SPAM = 0\n",
    "SPAM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "\n",
       "   category  \n",
       "0         0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('sms.parquet')\n",
    "df['category'] = df.apply(lambda r: SPAM if r['label'] == 'spam' else NOT_SPAM, axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text']], df[['category']], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function()\n",
    "def lf_keyword_my(x):\n",
    "    \"\"\"Many spam comments talk about 'my channel', 'my video', etc.\"\"\"\n",
    "    return SPAM if \"my\" in x.text.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "@labeling_function()\n",
    "def lf_regex_check_out(x):\n",
    "    \"\"\"Spam comments say 'check out my video', 'check it out', etc.\"\"\"\n",
    "    return SPAM if re.search(r\"check.*out\", x.text, flags=re.I) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_short_comment(x):\n",
    "    \"\"\"Non-spam comments are often short, such as 'cool video!'.\"\"\"\n",
    "    return NOT_SPAM if len(x.text.split()) < 5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "@labeling_function()\n",
    "def lf_textblob_polarity(x):\n",
    "    \"\"\"\n",
    "    We use a third-party sentiment classification model, TextBlob.\n",
    "\n",
    "    We combine this with the heuristic that non-spam comments are often positive.\n",
    "    \"\"\"\n",
    "    return NOT_SPAM if TextBlob(x.text).sentiment.polarity > 0.3 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4457 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▎         | 158/4457 [00:00<00:02, 1577.09it/s]\u001b[A\n",
      "  9%|▊         | 387/4457 [00:00<00:02, 1738.72it/s]\u001b[A\n",
      " 13%|█▎        | 596/4457 [00:00<00:02, 1830.92it/s]\u001b[A\n",
      " 19%|█▊        | 827/4457 [00:00<00:01, 1952.18it/s]\u001b[A\n",
      " 24%|██▍       | 1069/4457 [00:00<00:01, 2071.58it/s]\u001b[A\n",
      " 29%|██▉       | 1288/4457 [00:00<00:01, 2103.71it/s]\u001b[A\n",
      " 34%|███▍      | 1521/4457 [00:00<00:01, 2165.91it/s]\u001b[A\n",
      " 39%|███▉      | 1750/4457 [00:00<00:01, 2200.15it/s]\u001b[A\n",
      " 45%|████▍     | 1993/4457 [00:00<00:01, 2264.30it/s]\u001b[A\n",
      " 50%|████▉     | 2216/4457 [00:01<00:01, 2230.29it/s]\u001b[A\n",
      " 55%|█████▍    | 2443/4457 [00:01<00:00, 2242.02it/s]\u001b[A\n",
      " 60%|██████    | 2682/4457 [00:01<00:00, 2283.71it/s]\u001b[A\n",
      " 65%|██████▌   | 2919/4457 [00:01<00:00, 2308.03it/s]\u001b[A\n",
      " 71%|███████   | 3157/4457 [00:01<00:00, 2329.03it/s]\u001b[A\n",
      " 76%|███████▌  | 3397/4457 [00:01<00:00, 2349.20it/s]\u001b[A\n",
      " 81%|████████▏ | 3632/4457 [00:01<00:00, 2338.51it/s]\u001b[A\n",
      " 87%|████████▋ | 3874/4457 [00:01<00:00, 2361.16it/s]\u001b[A\n",
      " 92%|█████████▏| 4111/4457 [00:01<00:00, 2360.16it/s]\u001b[A\n",
      " 98%|█████████▊| 4353/4457 [00:01<00:00, 2375.69it/s]\u001b[A\n",
      "100%|██████████| 4457/4457 [00:01<00:00, 2268.85it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LabelModel, PandasLFApplier\n",
    "\n",
    "# Define the set of labeling functions (LFs)\n",
    "lfs = [lf_keyword_my, lf_regex_check_out, lf_short_comment, lf_textblob_polarity]\n",
    "\n",
    "# Apply the LFs to the unlabeled training data\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(X_train[['text']])\n",
    "\n",
    "# Train the label model and compute the training labels\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=500, log_freq=50, seed=123)\n",
    "X_train['label'] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2695\n",
       " 0    1386\n",
       " 1     376\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[X_train.label != ABSTAIN]\n",
    "y_train = X_train[['label']]\n",
    "X_train = X_train[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4394"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From text to a feature vector\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# bow_transform = text.CountVectorizer(max_features=500, min_df=0.0, max_df=1.0)\n",
    "bow_transform = text.CountVectorizer()\n",
    "X_train_bow = bow_transform.fit_transform(X_train['text'])\n",
    "X_text_bow = bow_transform.transform(X_test['text'])\n",
    "len(bow_transform.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (TF-IDF & L2 normalization) \n",
    "tfidf_trfm = text.TfidfTransformer(norm='l2')\n",
    "X_train_tfidf = tfidf_trfm.fit_transform(X_train_bow)\n",
    "X_test_tfidf = tfidf_trfm.transform(X_text_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=32,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7865470852017937"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=32)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
